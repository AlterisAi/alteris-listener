"""In-memory embedding index for semantic neighborhood retrieval.

Stores node embeddings as a numpy matrix for fast cosine similarity search.
At 384 dimensions and 100K nodes, the index is ~73MB in memory.
Embeddings are generated by a local model (Ollama) and cached in SQLite.
"""

from __future__ import annotations

import logging
import struct
import time
from typing import Optional

import numpy as np

from alteris_listener.graph.store import GraphStore

logger = logging.getLogger(__name__)


class EmbeddingIndex:
    """In-memory cosine similarity index over graph node embeddings.

    Loads embeddings from the graph database into a numpy matrix
    for fast similarity search. Designed for Apple Silicon — uses
    float16 to minimize memory while maintaining search quality.

    Usage:
        index = EmbeddingIndex(store, dim=384)
        index.load()                        # Load from DB
        results = index.search(query_vec, k=20)
        results = index.search_by_node_id("email:12345", k=20)
    """

    def __init__(self, store: GraphStore, dim: int = 384):
        self.store = store
        self.dim = dim
        self.ids: list[str] = []
        self.matrix: Optional[np.ndarray] = None  # (n, dim), float16, L2-normalized
        self._id_to_idx: dict[str, int] = {}

    @property
    def size(self) -> int:
        return len(self.ids)

    @property
    def memory_mb(self) -> float:
        if self.matrix is None:
            return 0.0
        return self.matrix.nbytes / (1024 * 1024)

    def load(self) -> int:
        """Load all embeddings from the graph database into memory.

        Returns the number of embeddings loaded.
        """
        start = time.time()

        rows = self.store.conn.execute(
            "SELECT id, embedding FROM nodes WHERE embedding IS NOT NULL"
        ).fetchall()

        if not rows:
            logger.info("No embeddings found in graph database")
            return 0

        ids = []
        vectors = []

        for row in rows:
            node_id = row["id"]
            emb_blob = row["embedding"]
            vec = blob_to_vector(emb_blob, self.dim)
            if vec is not None:
                ids.append(node_id)
                vectors.append(vec)

        if not vectors:
            return 0

        self.ids = ids
        self.matrix = np.array(vectors, dtype=np.float16)
        self._id_to_idx = {nid: i for i, nid in enumerate(ids)}

        # L2 normalize for cosine similarity via dot product
        norms = np.linalg.norm(self.matrix.astype(np.float32), axis=1, keepdims=True)
        norms = np.maximum(norms, 1e-8)
        self.matrix = (self.matrix.astype(np.float32) / norms).astype(np.float16)

        elapsed = time.time() - start
        logger.info(
            "Loaded %d embeddings (%d dim, %.1f MB) in %.2fs",
            len(ids), self.dim, self.memory_mb, elapsed,
        )
        return len(ids)

    def add(self, node_id: str, vector: np.ndarray):
        """Add a single embedding to the index (and persist to DB)."""
        # Normalize
        norm = np.linalg.norm(vector)
        if norm > 1e-8:
            vector = vector / norm

        vec_f16 = vector.astype(np.float16)

        # Store in DB
        blob = vector_to_blob(vec_f16)
        self.store.update_node_embedding(node_id, blob)

        # Add to in-memory index
        if node_id in self._id_to_idx:
            idx = self._id_to_idx[node_id]
            self.matrix[idx] = vec_f16
        else:
            self._id_to_idx[node_id] = len(self.ids)
            self.ids.append(node_id)
            if self.matrix is None:
                self.matrix = vec_f16.reshape(1, -1)
            else:
                self.matrix = np.vstack([self.matrix, vec_f16.reshape(1, -1)])

    def search(
        self,
        query_vector: np.ndarray,
        k: int = 20,
        exclude_ids: set[str] | None = None,
    ) -> list[tuple[str, float]]:
        """Find k most similar nodes to a query vector.

        Args:
            query_vector: Query embedding (will be normalized).
            k: Number of results.
            exclude_ids: Node IDs to exclude from results.

        Returns:
            List of (node_id, similarity) tuples, sorted by similarity desc.
        """
        if self.matrix is None or len(self.ids) == 0:
            return []

        # Normalize query
        query = query_vector.astype(np.float32)
        norm = np.linalg.norm(query)
        if norm > 1e-8:
            query = query / norm

        # Cosine similarity via dot product (vectors are pre-normalized)
        sims = self.matrix.astype(np.float32) @ query

        # Get top-k
        if exclude_ids:
            exclude_indices = {self._id_to_idx[nid] for nid in exclude_ids if nid in self._id_to_idx}
            for idx in exclude_indices:
                sims[idx] = -1.0

        top_k_count = min(k, len(sims))
        top_indices = np.argpartition(sims, -top_k_count)[-top_k_count:]
        top_indices = top_indices[np.argsort(sims[top_indices])[::-1]]

        return [(self.ids[i], float(sims[i])) for i in top_indices]

    def search_by_node_id(
        self,
        node_id: str,
        k: int = 20,
    ) -> list[tuple[str, float]]:
        """Find k most similar nodes to an existing node's embedding."""
        if node_id not in self._id_to_idx:
            return []

        idx = self._id_to_idx[node_id]
        query = self.matrix[idx].astype(np.float32)

        return self.search(query, k=k, exclude_ids={node_id})

    def get_vector(self, node_id: str) -> Optional[np.ndarray]:
        """Get the embedding vector for a node."""
        if node_id not in self._id_to_idx:
            return None
        idx = self._id_to_idx[node_id]
        return self.matrix[idx].astype(np.float32)


# ══════════════════════════════════════════════════════════════════
# Serialization helpers (vector ↔ blob for SQLite)
# ══════════════════════════════════════════════════════════════════


def vector_to_blob(vec: np.ndarray) -> bytes:
    """Convert a numpy vector to bytes for SQLite storage."""
    return vec.astype(np.float16).tobytes()


def blob_to_vector(blob: bytes, dim: int) -> Optional[np.ndarray]:
    """Convert a SQLite blob back to a numpy vector."""
    try:
        vec = np.frombuffer(blob, dtype=np.float16)
        if len(vec) != dim:
            logger.warning("Embedding dimension mismatch: expected %d, got %d", dim, len(vec))
            return None
        return vec
    except (ValueError, struct.error):
        return None
